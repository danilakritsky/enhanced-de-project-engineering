<div align="center">
  <img src="docs/repo-logo.png" alt="prompt engineering logo" width="300"/>
</div>

# Enhanced DE Prompt Engineering

This repository contains experiments and solutions for data engineering tasks using prompt engineering techniques.

## Task 1: Revenue Report Optimization

This task focused on optimizing a PostgreSQL query used to generate a nightly revenue and refunds report. The original query performance had degraded, exceeding the required SLA of 15 seconds.

The process involved analyzing the original query, identifying performance bottlenecks, proposing and evaluating optimization strategies (specifically CTEs vs. Window Functions), recommending indexing, implementing the chosen solution, and setting up automated testing and benchmarking.

## Task 2: Sales Data Analysis using SQL (SQLite)

This task involved creating and validating SQL queries for analyzing sales data stored in an SQLite database. The work followed a Test-Driven Development (TDD) approach.

The process included creating SQL queries for specific analysis tasks (total March 2024 sales, top customer by spend, average order value over the last three months), developing corresponding automated tests using pytest and an in-memory SQLite database with data from `task_02.md`, and documenting the queries and validation process.

### Project Structure

The relevant parts of the project structure are:

-   `.cursor/rules/`: Contains configuration files (`.mdc`) that define rules and guidelines for the AI agent.
-   `analyses/`: Contains analysis documents. These files detail query logic, optimization strategies, validation steps, and results for each task (Generated by Cursor).
    -   `analysis_task_01.md`: Analysis for Task 1.
    -   `analysis_task_02.md`: Analysis for Task 2.
-   `chatgpt_prompts/`: Contains the initial prompts provided to ChatGPT to generate the task execution plans.
-   `cursor_chats/`: Contains exported chat transcripts from Cursor, documenting the development process and task execution.
-   `docker-compose.yml`: Docker setup for the test PostgreSQL database.
-   `prompt_plans/`: Contains task execution plans generated by ChatGPT based on the initial prompts.
    -   `plan_task_01.md`: Plan for Task 1.
    -   `plan_task_02.md`: Plan for Task 2.
-   `pyproject.toml`: Project dependencies and configuration.
-   `queries/`: Contains SQL query files.
    -   `task_01/`: SQL queries for Task 1 (PostgreSQL).
    -   `task_02/`: SQL queries for Task 2 (SQLite).
-   `tests/`: Contains the test suite.
    -   `test_revenue_report_postgres.py`: Pytest tests for Task 1.
    -   `test_sales_analysis_sqlite.py`: Pytest tests for Task 2.
    -   `conftest.py`: Pytest fixtures, including the PostgreSQL connection setup.
-   `tasks/`: Contains task definitions.
    -   `task_01.md`: Definition for Task 1.
    -   `task_02.md`: Definition for Task 2.
-   `utils/`: Contains utility functions.
    -   `benchmark.py`: Functions for query benchmarking.

### Setting up the Test Database (Docker)

The PostgreSQL test suite requires a running database. Use Docker Compose to manage this service:

1.  Ensure Docker and Docker Compose are installed.
2.  Navigate to the repository root.
3.  Start the PostgreSQL container:

    ```bash
    docker compose -f docker/docker-compose.yml --project-directory docker/ up -d postgres
    ```
    *Note: After starting the container, you may need to wait a few moments for the database service inside the container to be fully ready before running tests. The pytest fixture for PostgreSQL includes retry logic to handle brief startup delays.*

4.  To stop the container:

    ```bash
    docker compose -f docker/docker-compose.yml --project-directory docker/ down
    ```

### Development Dependencies

The project uses `uv` for dependency management. Install dependencies with:

```bash
uv sync
```

### Running Tests and Checks

Automated checks (linting, formatting, tests) are configured with pre-commit. Run all checks using `uv`:

```bash
uv run pre-commit run --all-files
```

Alternatively, run pytest directly:

```bash
uv run python -m pytest tests/
```

### Using the Makefile

A `Makefile` is provided in the root directory as a convenient way to run common project tasks. You can execute these tasks using the `make` command followed by the target name.

Available targets:

*   `make install`: Installs project dependencies using `uv sync`.

*   `make check`: Runs all pre-commit checks (`uv run pre-commit run --all-files`).

*   `make test`: Runs the pytest test suite (`uv run python -m pytest tests/`).

*   `make db-up`: Starts the PostgreSQL test database container (`docker compose -f docker/docker-compose.yml --project-directory docker/ up -d postgres`).

*   `make db-down`: Stops the PostgreSQL test database container (`docker compose -f docker/docker-compose.yml --project-directory docker/ down`).

*   `make all` (default): Runs `install`, `check`, and `test` in sequence.

### MCP Servers Used

No MCP (Managed Cloud Platform) servers were used during the development of these tasks. All development and testing were conducted locally using an in-memory SQLite database for Task 2 and a local PostgreSQL database managed via Docker Compose for Task 1.
